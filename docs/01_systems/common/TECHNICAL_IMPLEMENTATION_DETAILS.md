# ğŸ”§ çµ±åˆãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ æŠ€è¡“å®Ÿè£…è©³ç´°æ›¸

**ä½œæˆæ—¥**: 2025å¹´9æœˆ24æ—¥  
**å¯¾è±¡**: hotel-commoné–‹ç™ºãƒãƒ¼ãƒ   
**å‰æ**: `/Users/kaneko/hotel-kanri/docs/01_systems/common/UNIFIED_LOG_SYSTEM_DESIGN.md` ç†Ÿèª­å¿…é ˆ  

---

## âš ï¸ ã€é‡è¦ã€‘æ—¢å­˜å®Ÿè£…ã¨ã®é‡è¤‡å›é¿

### **âŒ çµ¶å¯¾ã«å®Ÿè£…ã—ã¦ã¯ã„ã‘ãªã„æ©Ÿèƒ½**
1. **JWTèªè¨¼ã‚·ã‚¹ãƒ†ãƒ ** - æ—¢ã«çµ±åˆå®Ÿè£…æ¸ˆã¿
2. **APIèªè¨¼ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢** - æ—¢å­˜ã®çµ±ä¸€èªè¨¼ã‚’ä½¿ç”¨
3. **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç®¡ç†** - æ—¢å­˜ã®Prismaçµ±åˆã‚’ä½¿ç”¨
4. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°åŸºç›¤** - æ—¢å­˜ã®çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨
5. **ãƒ¢ãƒƒã‚¯ãƒ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè£…** - æœ¬ç•ªç”¨å®Ÿè£…ã®ã¿

### **âœ… æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®é€£æºæ–¹æ³•**
```typescript
// âŒ æ–°è¦JWTå®Ÿè£…ï¼ˆç¦æ­¢ï¼‰
// const jwt = new JWTService()

// âœ… æ—¢å­˜çµ±ä¸€èªè¨¼ã®åˆ©ç”¨
import { UnifiedAuth } from '../auth/unified-auth'
const auth = UnifiedAuth.getInstance()
```

---

## ğŸ—„ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒå®Ÿè£…

### **1. ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆSQLï¼ˆå®Œå…¨ç‰ˆï¼‰**

#### **auth_logs ãƒ†ãƒ¼ãƒ–ãƒ«**
```sql
-- èªè¨¼ãƒ­ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE auth_logs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  system VARCHAR(20) NOT NULL CHECK (system IN ('saas', 'pms', 'member', 'common')),
  tenant_id UUID,
  user_id UUID NOT NULL,
  email VARCHAR(255) NOT NULL,
  action VARCHAR(50) NOT NULL CHECK (action IN ('LOGIN_SUCCESS', 'LOGIN_FAILED', 'LOGOUT', 'TOKEN_REFRESH', 'PASSWORD_CHANGE')),
  ip_address INET,
  user_agent TEXT,
  session_id VARCHAR(255),
  failure_reason VARCHAR(255),
  device_info JSONB DEFAULT '{}',
  location_info JSONB DEFAULT '{}',
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  
  -- åˆ¶ç´„
  CONSTRAINT auth_logs_tenant_check CHECK (
    (system IN ('saas', 'pms', 'member') AND tenant_id IS NOT NULL) OR
    (system = 'common' AND tenant_id IS NULL)
  )
);

-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX idx_auth_logs_system_created ON auth_logs (system, created_at DESC);
CREATE INDEX idx_auth_logs_user_action ON auth_logs (user_id, action);
CREATE INDEX idx_auth_logs_tenant_created ON auth_logs (tenant_id, created_at DESC) WHERE tenant_id IS NOT NULL;
CREATE INDEX idx_auth_logs_ip_created ON auth_logs (ip_address, created_at DESC);
CREATE INDEX idx_auth_logs_session ON auth_logs (session_id) WHERE session_id IS NOT NULL;
CREATE INDEX idx_auth_logs_failure ON auth_logs (action, failure_reason) WHERE action = 'LOGIN_FAILED';

-- ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ï¼ˆæœˆåˆ¥ï¼‰
CREATE TABLE auth_logs_2025_09 PARTITION OF auth_logs
FOR VALUES FROM ('2025-09-01') TO ('2025-10-01');

CREATE TABLE auth_logs_2025_10 PARTITION OF auth_logs
FOR VALUES FROM ('2025-10-01') TO ('2025-11-01');

-- è‡ªå‹•ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ä½œæˆé–¢æ•°
CREATE OR REPLACE FUNCTION create_auth_logs_partition(target_date DATE)
RETURNS VOID AS $$
DECLARE
    partition_name TEXT;
    start_date DATE;
    end_date DATE;
BEGIN
    start_date := DATE_TRUNC('month', target_date);
    end_date := start_date + INTERVAL '1 month';
    partition_name := 'auth_logs_' || TO_CHAR(start_date, 'YYYY_MM');
    
    EXECUTE format('CREATE TABLE IF NOT EXISTS %I PARTITION OF auth_logs FOR VALUES FROM (%L) TO (%L)',
                   partition_name, start_date, end_date);
END;
$$ LANGUAGE plpgsql;
```

#### **security_logs ãƒ†ãƒ¼ãƒ–ãƒ«**
```sql
-- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE security_logs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  system VARCHAR(20) NOT NULL CHECK (system IN ('saas', 'pms', 'member', 'common')),
  tenant_id UUID,
  user_id UUID,
  event_type VARCHAR(100) NOT NULL,
  severity VARCHAR(20) NOT NULL CHECK (severity IN ('LOW', 'MEDIUM', 'HIGH', 'CRITICAL')),
  description TEXT NOT NULL,
  details JSONB DEFAULT '{}',
  ip_address INET,
  user_agent TEXT,
  request_path VARCHAR(500),
  request_method VARCHAR(10) CHECK (request_method IN ('GET', 'POST', 'PUT', 'DELETE', 'PATCH')),
  response_code INTEGER,
  blocked BOOLEAN DEFAULT FALSE,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  
  -- åˆ¶ç´„
  CONSTRAINT security_logs_tenant_check CHECK (
    (system IN ('saas', 'pms', 'member') AND tenant_id IS NOT NULL) OR
    (system = 'common')
  )
);

-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX idx_security_logs_severity_created ON security_logs (severity, created_at DESC);
CREATE INDEX idx_security_logs_system_event ON security_logs (system, event_type);
CREATE INDEX idx_security_logs_ip_created ON security_logs (ip_address, created_at DESC);
CREATE INDEX idx_security_logs_tenant_created ON security_logs (tenant_id, created_at DESC) WHERE tenant_id IS NOT NULL;
CREATE INDEX idx_security_logs_blocked ON security_logs (blocked, created_at DESC) WHERE blocked = true;
CREATE INDEX idx_security_logs_critical ON security_logs (severity, created_at DESC) WHERE severity IN ('HIGH', 'CRITICAL');

-- ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ï¼ˆæœˆåˆ¥ï¼‰
CREATE TABLE security_logs_2025_09 PARTITION OF security_logs
FOR VALUES FROM ('2025-09-01') TO ('2025-10-01');
```

#### **system_batch_logs ãƒ†ãƒ¼ãƒ–ãƒ«**
```sql
-- ã‚·ã‚¹ãƒ†ãƒ å‡¦ç†ãƒ­ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE system_batch_logs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  system VARCHAR(20) NOT NULL CHECK (system IN ('saas', 'pms', 'member', 'common')),
  tenant_id UUID,
  job_name VARCHAR(255) NOT NULL,
  job_type VARCHAR(100) NOT NULL CHECK (job_type IN ('BATCH', 'SYNC', 'CLEANUP', 'MIGRATION', 'BACKUP')),
  status VARCHAR(50) NOT NULL CHECK (status IN ('STARTED', 'SUCCESS', 'FAILED', 'TIMEOUT', 'CANCELLED')),
  start_time TIMESTAMP WITH TIME ZONE,
  end_time TIMESTAMP WITH TIME ZONE,
  duration_ms INTEGER GENERATED ALWAYS AS (
    CASE WHEN end_time IS NOT NULL AND start_time IS NOT NULL 
    THEN EXTRACT(EPOCH FROM (end_time - start_time)) * 1000 
    ELSE NULL END
  ) STORED,
  processed_count INTEGER DEFAULT 0 CHECK (processed_count >= 0),
  success_count INTEGER DEFAULT 0 CHECK (success_count >= 0),
  error_count INTEGER DEFAULT 0 CHECK (error_count >= 0),
  error_message TEXT,
  details JSONB DEFAULT '{}',
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  
  -- åˆ¶ç´„
  CONSTRAINT batch_logs_counts_check CHECK (success_count + error_count <= processed_count),
  CONSTRAINT batch_logs_time_check CHECK (end_time IS NULL OR end_time >= start_time)
);

-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX idx_batch_logs_system_status ON system_batch_logs (system, status);
CREATE INDEX idx_batch_logs_job_created ON system_batch_logs (job_name, created_at DESC);
CREATE INDEX idx_batch_logs_tenant_created ON system_batch_logs (tenant_id, created_at DESC) WHERE tenant_id IS NOT NULL;
CREATE INDEX idx_batch_logs_failed ON system_batch_logs (status, created_at DESC) WHERE status IN ('FAILED', 'TIMEOUT');
```

#### **integration_logs ãƒ†ãƒ¼ãƒ–ãƒ«**
```sql
-- ã‚·ã‚¹ãƒ†ãƒ é–“é€£æºãƒ­ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE integration_logs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  source_system VARCHAR(20) NOT NULL CHECK (source_system IN ('saas', 'pms', 'member', 'common')),
  target_system VARCHAR(20) NOT NULL CHECK (target_system IN ('saas', 'pms', 'member', 'common')),
  tenant_id UUID,
  operation VARCHAR(100) NOT NULL,
  endpoint VARCHAR(500),
  request_method VARCHAR(10) CHECK (request_method IN ('GET', 'POST', 'PUT', 'DELETE', 'PATCH')),
  request_data JSONB DEFAULT '{}',
  response_data JSONB DEFAULT '{}',
  status VARCHAR(50) NOT NULL CHECK (status IN ('SUCCESS', 'FAILED', 'TIMEOUT', 'RETRY')),
  response_code INTEGER,
  response_time_ms INTEGER CHECK (response_time_ms >= 0),
  retry_count INTEGER DEFAULT 0 CHECK (retry_count >= 0),
  error_message TEXT,
  correlation_id VARCHAR(255),
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  
  -- åˆ¶ç´„
  CONSTRAINT integration_logs_systems_check CHECK (source_system != target_system)
);

-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX idx_integration_logs_systems ON integration_logs (source_system, target_system);
CREATE INDEX idx_integration_logs_operation ON integration_logs (operation, created_at DESC);
CREATE INDEX idx_integration_logs_status ON integration_logs (status, created_at DESC);
CREATE INDEX idx_integration_logs_tenant ON integration_logs (tenant_id, created_at DESC) WHERE tenant_id IS NOT NULL;
CREATE INDEX idx_integration_logs_correlation ON integration_logs (correlation_id) WHERE correlation_id IS NOT NULL;
CREATE INDEX idx_integration_logs_failed ON integration_logs (status, created_at DESC) WHERE status IN ('FAILED', 'TIMEOUT');
```

### **2. Row Level Security (RLS) è¨­å®š**
```sql
-- RLSæœ‰åŠ¹åŒ–
ALTER TABLE auth_logs ENABLE ROW LEVEL SECURITY;
ALTER TABLE security_logs ENABLE ROW LEVEL SECURITY;
ALTER TABLE system_batch_logs ENABLE ROW LEVEL SECURITY;
ALTER TABLE integration_logs ENABLE ROW LEVEL SECURITY;

-- ãƒ†ãƒŠãƒ³ãƒˆåˆ†é›¢ãƒãƒªã‚·ãƒ¼
CREATE POLICY tenant_isolation_auth_logs ON auth_logs
  FOR ALL TO authenticated
  USING (tenant_id = current_setting('app.current_tenant_id')::UUID OR current_setting('app.user_role') = 'SYSTEM_ADMIN');

CREATE POLICY tenant_isolation_security_logs ON security_logs
  FOR ALL TO authenticated
  USING (tenant_id = current_setting('app.current_tenant_id')::UUID OR current_setting('app.user_role') = 'SYSTEM_ADMIN');

CREATE POLICY tenant_isolation_batch_logs ON system_batch_logs
  FOR ALL TO authenticated
  USING (tenant_id = current_setting('app.current_tenant_id')::UUID OR current_setting('app.user_role') = 'SYSTEM_ADMIN');

CREATE POLICY tenant_isolation_integration_logs ON integration_logs
  FOR ALL TO authenticated
  USING (tenant_id = current_setting('app.current_tenant_id')::UUID OR current_setting('app.user_role') = 'SYSTEM_ADMIN');

-- ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ç”¨ãƒãƒªã‚·ãƒ¼
CREATE POLICY system_admin_full_access ON auth_logs
  FOR ALL TO authenticated
  USING (current_setting('app.user_role') = 'SYSTEM_ADMIN');
```

---

## ğŸ”§ APIå®Ÿè£…è©³ç´°

### **1. ãƒ­ã‚°è¨˜éŒ²APIå®Ÿè£…**

#### **èªè¨¼ãƒ­ã‚°è¨˜éŒ²API**
```typescript
// server/api/v1/logs/auth.post.ts
import { z } from 'zod'
import { LogQueue } from '~/server/utils/log-queue'
import { UnifiedAuth } from '~/server/utils/unified-auth'

const AuthLogSchema = z.object({
  system: z.enum(['saas', 'pms', 'member', 'common']),
  tenant_id: z.string().uuid().optional(),
  user_id: z.string().uuid(),
  email: z.string().email(),
  action: z.enum(['LOGIN_SUCCESS', 'LOGIN_FAILED', 'LOGOUT', 'TOKEN_REFRESH', 'PASSWORD_CHANGE']),
  ip_address: z.string().ip().optional(),
  user_agent: z.string().optional(),
  session_id: z.string().optional(),
  failure_reason: z.string().optional(),
  device_info: z.record(z.any()).optional(),
  location_info: z.record(z.any()).optional()
})

export default defineEventHandler(async (event) => {
  try {
    // æ—¢å­˜çµ±ä¸€èªè¨¼ã‚’ä½¿ç”¨ï¼ˆé‡è¤‡å®Ÿè£…ç¦æ­¢ï¼‰
    const auth = await UnifiedAuth.validateSystemToken(event)
    if (!auth.isSystemUser) {
      throw createError({
        statusCode: 403,
        statusMessage: 'System authentication required'
      })
    }

    const body = await readBody(event)
    const validatedData = AuthLogSchema.parse(body)

    // ãƒ†ãƒŠãƒ³ãƒˆIDæ¤œè¨¼
    if (['saas', 'pms', 'member'].includes(validatedData.system) && !validatedData.tenant_id) {
      throw createError({
        statusCode: 400,
        statusMessage: 'tenant_id is required for non-common systems'
      })
    }

    // éåŒæœŸãƒ­ã‚°è¨˜éŒ²ï¼ˆæ—¢å­˜ã‚­ãƒ¥ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ï¼‰
    await LogQueue.enqueue('auth_log', {
      ...validatedData,
      created_at: new Date().toISOString()
    })

    // é«˜é‡è¦åº¦ãƒ­ã‚°ã®å³åº§ã‚¢ãƒ©ãƒ¼ãƒˆ
    if (validatedData.action === 'LOGIN_FAILED' && validatedData.failure_reason) {
      await AlertService.sendSecurityAlert({
        type: 'LOGIN_FAILURE',
        severity: 'MEDIUM',
        details: validatedData
      })
    }

    return {
      success: true,
      message: 'Auth log recorded successfully'
    }

  } catch (error) {
    // æ—¢å­˜çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨
    return handleUnifiedError(error, event)
  }
})
```

#### **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ­ã‚°è¨˜éŒ²API**
```typescript
// server/api/v1/logs/security.post.ts
import { z } from 'zod'
import { LogQueue } from '~/server/utils/log-queue'
import { AlertService } from '~/server/utils/alert-service'

const SecurityLogSchema = z.object({
  system: z.enum(['saas', 'pms', 'member', 'common']),
  tenant_id: z.string().uuid().optional(),
  user_id: z.string().uuid().optional(),
  event_type: z.string().min(1).max(100),
  severity: z.enum(['LOW', 'MEDIUM', 'HIGH', 'CRITICAL']),
  description: z.string().min(1),
  details: z.record(z.any()).optional(),
  ip_address: z.string().ip().optional(),
  user_agent: z.string().optional(),
  request_path: z.string().max(500).optional(),
  request_method: z.enum(['GET', 'POST', 'PUT', 'DELETE', 'PATCH']).optional(),
  response_code: z.number().int().min(100).max(599).optional(),
  blocked: z.boolean().optional()
})

export default defineEventHandler(async (event) => {
  try {
    const auth = await UnifiedAuth.validateSystemToken(event)
    if (!auth.isSystemUser) {
      throw createError({
        statusCode: 403,
        statusMessage: 'System authentication required'
      })
    }

    const body = await readBody(event)
    const validatedData = SecurityLogSchema.parse(body)

    // éåŒæœŸãƒ­ã‚°è¨˜éŒ²
    await LogQueue.enqueue('security_log', {
      ...validatedData,
      created_at: new Date().toISOString()
    })

    // é‡è¦åº¦ã«å¿œã˜ãŸå³åº§ã‚¢ãƒ©ãƒ¼ãƒˆ
    if (['HIGH', 'CRITICAL'].includes(validatedData.severity)) {
      await AlertService.sendSecurityAlert({
        type: 'SECURITY_INCIDENT',
        severity: validatedData.severity,
        details: validatedData,
        immediate: validatedData.severity === 'CRITICAL'
      })
    }

    return {
      success: true,
      message: 'Security log recorded successfully'
    }

  } catch (error) {
    return handleUnifiedError(error, event)
  }
})
```

### **2. ãƒ­ã‚°æ¤œç´¢APIå®Ÿè£…**

```typescript
// server/api/v1/logs/search.get.ts
import { z } from 'zod'
import { UnifiedDatabase } from '~/server/utils/unified-database'

const SearchQuerySchema = z.object({
  systems: z.array(z.enum(['saas', 'pms', 'member', 'common'])).optional(),
  log_types: z.array(z.enum(['auth', 'security', 'batch', 'integration'])).optional(),
  tenant_id: z.string().uuid().optional(),
  user_id: z.string().uuid().optional(),
  start_date: z.string().datetime().optional(),
  end_date: z.string().datetime().optional(),
  severity: z.enum(['LOW', 'MEDIUM', 'HIGH', 'CRITICAL']).optional(),
  status: z.string().optional(),
  limit: z.number().int().min(1).max(1000).default(100),
  offset: z.number().int().min(0).default(0)
})

export default defineEventHandler(async (event) => {
  try {
    const auth = await UnifiedAuth.validateToken(event)
    if (!auth.isAuthenticated || !auth.hasPermission('logs.read')) {
      throw createError({
        statusCode: 403,
        statusMessage: 'Insufficient permissions'
      })
    }

    const query = getQuery(event)
    const validatedQuery = SearchQuerySchema.parse(query)

    // ãƒ†ãƒŠãƒ³ãƒˆåˆ†é›¢ã®é©ç”¨
    const tenantFilter = auth.isSystemAdmin ? 
      validatedQuery.tenant_id : auth.tenantId

    const results = await searchUnifiedLogs({
      ...validatedQuery,
      tenant_id: tenantFilter,
      user_permissions: auth.permissions
    })

    return {
      success: true,
      data: {
        logs: results.logs,
        total_count: results.totalCount,
        has_more: results.hasMore
      }
    }

  } catch (error) {
    return handleUnifiedError(error, event)
  }
})

// ãƒ­ã‚°æ¤œç´¢å®Ÿè£…
async function searchUnifiedLogs(params: SearchParams) {
  const db = UnifiedDatabase.getInstance()
  
  // å‹•çš„ã‚¯ã‚¨ãƒªæ§‹ç¯‰
  let baseQuery = `
    SELECT 
      'auth' as log_type, id, system, tenant_id, created_at,
      jsonb_build_object(
        'user_id', user_id,
        'email', email,
        'action', action,
        'ip_address', ip_address,
        'session_id', session_id
      ) as data
    FROM auth_logs
    WHERE 1=1
  `

  const queryParams: any[] = []
  let paramIndex = 1

  // ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚£ãƒ«ã‚¿
  if (params.systems?.length) {
    baseQuery += ` AND system = ANY($${paramIndex})`
    queryParams.push(params.systems)
    paramIndex++
  }

  // ãƒ†ãƒŠãƒ³ãƒˆãƒ•ã‚£ãƒ«ã‚¿
  if (params.tenant_id) {
    baseQuery += ` AND tenant_id = $${paramIndex}`
    queryParams.push(params.tenant_id)
    paramIndex++
  }

  // æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿
  if (params.start_date) {
    baseQuery += ` AND created_at >= $${paramIndex}`
    queryParams.push(params.start_date)
    paramIndex++
  }

  if (params.end_date) {
    baseQuery += ` AND created_at <= $${paramIndex}`
    queryParams.push(params.end_date)
    paramIndex++
  }

  // ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³
  baseQuery += ` ORDER BY created_at DESC LIMIT $${paramIndex} OFFSET $${paramIndex + 1}`
  queryParams.push(params.limit, params.offset)

  const result = await db.query(baseQuery, queryParams)
  
  return {
    logs: result.rows,
    totalCount: await getTotalCount(params),
    hasMore: result.rows.length === params.limit
  }
}
```

---

## ğŸš€ Redis Queueå®Ÿè£…

### **1. ãƒ­ã‚°ã‚­ãƒ¥ãƒ¼ã‚·ã‚¹ãƒ†ãƒ **

```typescript
// server/utils/log-queue.ts
import Redis from 'ioredis'
import { UnifiedDatabase } from './unified-database'

class LogQueueService {
  private redis: Redis
  private isProcessing = false

  constructor() {
    // æ—¢å­˜Redisæ¥ç¶šã‚’ä½¿ç”¨ï¼ˆé‡è¤‡å®Ÿè£…ç¦æ­¢ï¼‰
    this.redis = UnifiedRedis.getInstance()
    this.startWorker()
  }

  async enqueue(logType: string, data: any): Promise<void> {
    const queueKey = `log_queue:${logType}`
    const payload = {
      id: crypto.randomUUID(),
      type: logType,
      data,
      timestamp: Date.now(),
      retryCount: 0
    }

    await this.redis.lpush(queueKey, JSON.stringify(payload))
  }

  private async startWorker(): Promise<void> {
    if (this.isProcessing) return
    this.isProcessing = true

    const logTypes = ['auth_log', 'security_log', 'batch_log', 'integration_log']
    
    while (this.isProcessing) {
      try {
        for (const logType of logTypes) {
          await this.processQueue(logType)
        }
        await new Promise(resolve => setTimeout(resolve, 1000)) // 1ç§’å¾…æ©Ÿ
      } catch (error) {
        console.error('Log queue worker error:', error)
        await new Promise(resolve => setTimeout(resolve, 5000)) // ã‚¨ãƒ©ãƒ¼æ™‚ã¯5ç§’å¾…æ©Ÿ
      }
    }
  }

  private async processQueue(logType: string): Promise<void> {
    const queueKey = `log_queue:${logType}`
    const item = await this.redis.brpop(queueKey, 1) // 1ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ

    if (!item) return

    try {
      const payload = JSON.parse(item[1])
      await this.writeToDatabase(payload)
    } catch (error) {
      console.error(`Failed to process ${logType}:`, error)
      // ãƒªãƒˆãƒ©ã‚¤å‡¦ç†
      await this.handleRetry(logType, item[1])
    }
  }

  private async writeToDatabase(payload: any): Promise<void> {
    const db = UnifiedDatabase.getInstance()

    switch (payload.type) {
      case 'auth_log':
        await db.query(`
          INSERT INTO auth_logs (
            system, tenant_id, user_id, email, action, 
            ip_address, user_agent, session_id, failure_reason,
            device_info, location_info, created_at
          ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12)
        `, [
          payload.data.system,
          payload.data.tenant_id,
          payload.data.user_id,
          payload.data.email,
          payload.data.action,
          payload.data.ip_address,
          payload.data.user_agent,
          payload.data.session_id,
          payload.data.failure_reason,
          payload.data.device_info || {},
          payload.data.location_info || {},
          payload.data.created_at
        ])
        break

      case 'security_log':
        await db.query(`
          INSERT INTO security_logs (
            system, tenant_id, user_id, event_type, severity,
            description, details, ip_address, user_agent,
            request_path, request_method, response_code, blocked, created_at
          ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)
        `, [
          payload.data.system,
          payload.data.tenant_id,
          payload.data.user_id,
          payload.data.event_type,
          payload.data.severity,
          payload.data.description,
          payload.data.details || {},
          payload.data.ip_address,
          payload.data.user_agent,
          payload.data.request_path,
          payload.data.request_method,
          payload.data.response_code,
          payload.data.blocked || false,
          payload.data.created_at
        ])
        break

      // ä»–ã®ãƒ­ã‚°ã‚¿ã‚¤ãƒ—ã‚‚åŒæ§˜ã«å®Ÿè£…
    }
  }

  private async handleRetry(logType: string, payloadStr: string): Promise<void> {
    const payload = JSON.parse(payloadStr)
    payload.retryCount = (payload.retryCount || 0) + 1

    if (payload.retryCount <= 3) {
      // æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§ãƒªãƒˆãƒ©ã‚¤
      const delay = Math.pow(2, payload.retryCount) * 1000
      setTimeout(async () => {
        await this.redis.lpush(`log_queue:${logType}`, JSON.stringify(payload))
      }, delay)
    } else {
      // æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã‚’è¶…ãˆãŸå ´åˆã¯ãƒ‡ãƒƒãƒ‰ãƒ¬ã‚¿ãƒ¼ã‚­ãƒ¥ãƒ¼ã«é€ä¿¡
      await this.redis.lpush(`log_queue:${logType}:dead`, payloadStr)
    }
  }
}

export const LogQueue = new LogQueueService()
```

---

## ğŸ“Š ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆå®Ÿè£…

### **1. ã‚¢ãƒ©ãƒ¼ãƒˆã‚µãƒ¼ãƒ“ã‚¹**

```typescript
// server/utils/alert-service.ts
import { UnifiedNotification } from './unified-notification'

interface AlertConfig {
  type: string
  severity: 'LOW' | 'MEDIUM' | 'HIGH' | 'CRITICAL'
  details: any
  immediate?: boolean
}

class AlertServiceClass {
  async sendSecurityAlert(config: AlertConfig): Promise<void> {
    // æ—¢å­˜çµ±ä¸€é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ï¼ˆé‡è¤‡å®Ÿè£…ç¦æ­¢ï¼‰
    const notification = UnifiedNotification.getInstance()

    const message = this.formatAlertMessage(config)
    const channels = this.getAlertChannels(config.severity)

    for (const channel of channels) {
      switch (channel.type) {
        case 'slack':
          await notification.sendSlack({
            webhook: channel.webhook,
            message,
            severity: config.severity,
            immediate: config.immediate
          })
          break

        case 'email':
          await notification.sendEmail({
            to: channel.recipients,
            subject: `Security Alert: ${config.type}`,
            body: message,
            priority: config.severity === 'CRITICAL' ? 'high' : 'normal'
          })
          break
      }
    }
  }

  private formatAlertMessage(config: AlertConfig): string {
    return `
ğŸš¨ Security Alert: ${config.type}
Severity: ${config.severity}
Time: ${new Date().toISOString()}
System: ${config.details.system || 'Unknown'}
Tenant: ${config.details.tenant_id || 'N/A'}
Details: ${JSON.stringify(config.details, null, 2)}
    `.trim()
  }

  private getAlertChannels(severity: string) {
    const channels = []

    // é‡è¦åº¦ã«å¿œã˜ãŸé€šçŸ¥ãƒãƒ£ãƒ³ãƒãƒ«
    if (['HIGH', 'CRITICAL'].includes(severity)) {
      channels.push({
        type: 'slack',
        webhook: process.env.SLACK_SECURITY_WEBHOOK_URL
      })
    }

    if (severity === 'CRITICAL') {
      channels.push({
        type: 'email',
        recipients: process.env.SECURITY_ALERT_EMAILS?.split(',') || []
      })
    }

    return channels
  }
}

export const AlertService = new AlertServiceClass()
```

---

## ğŸ”’ ç’°å¢ƒè¨­å®š

### **1. ç’°å¢ƒå¤‰æ•°ï¼ˆå®Œå…¨ç‰ˆï¼‰**

```bash
# .env.example
# ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
LOG_DB_HOST=localhost
LOG_DB_PORT=5432
LOG_DB_NAME=hotel_unified_logs
LOG_DB_USER=hotel_log_user
LOG_DB_PASSWORD=secure_password_here

# Redisè¨­å®šï¼ˆæ—¢å­˜çµ±ä¸€Redisã‚’ä½¿ç”¨ï¼‰
REDIS_LOG_QUEUE_URL=redis://localhost:6379/2

# ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
SLACK_SECURITY_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL
SECURITY_ALERT_EMAILS=admin@hotel.com,security@hotel.com

# ãƒ­ã‚°ä¿æŒæœŸé–“
LOG_RETENTION_AUTH_DAYS=730        # 2å¹´
LOG_RETENTION_SECURITY_DAYS=2555   # 7å¹´
LOG_RETENTION_BATCH_DAYS=365       # 1å¹´
LOG_RETENTION_INTEGRATION_DAYS=180 # 6ãƒ¶æœˆ

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®š
LOG_QUEUE_BATCH_SIZE=100
LOG_QUEUE_PROCESS_INTERVAL=1000    # ãƒŸãƒªç§’
LOG_SEARCH_MAX_RESULTS=1000

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š
LOG_API_RATE_LIMIT=1000            # 1æ™‚é–“ã‚ãŸã‚Šã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°
LOG_ENCRYPTION_KEY=your_32_char_encryption_key_here
```

### **2. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«**

```typescript
// config/log-system.ts
export const LogSystemConfig = {
  database: {
    host: process.env.LOG_DB_HOST || 'localhost',
    port: parseInt(process.env.LOG_DB_PORT || '5432'),
    database: process.env.LOG_DB_NAME || 'hotel_unified_logs',
    username: process.env.LOG_DB_USER || 'hotel_log_user',
    password: process.env.LOG_DB_PASSWORD,
    ssl: process.env.NODE_ENV === 'production',
    pool: {
      min: 2,
      max: 20,
      idleTimeoutMillis: 30000,
      connectionTimeoutMillis: 2000
    }
  },

  redis: {
    url: process.env.REDIS_LOG_QUEUE_URL || 'redis://localhost:6379/2',
    retryDelayOnFailover: 100,
    maxRetriesPerRequest: 3
  },

  retention: {
    auth_logs: parseInt(process.env.LOG_RETENTION_AUTH_DAYS || '730'),
    security_logs: parseInt(process.env.LOG_RETENTION_SECURITY_DAYS || '2555'),
    system_batch_logs: parseInt(process.env.LOG_RETENTION_BATCH_DAYS || '365'),
    integration_logs: parseInt(process.env.LOG_RETENTION_INTEGRATION_DAYS || '180')
  },

  performance: {
    queueBatchSize: parseInt(process.env.LOG_QUEUE_BATCH_SIZE || '100'),
    processInterval: parseInt(process.env.LOG_QUEUE_PROCESS_INTERVAL || '1000'),
    searchMaxResults: parseInt(process.env.LOG_SEARCH_MAX_RESULTS || '1000')
  },

  security: {
    apiRateLimit: parseInt(process.env.LOG_API_RATE_LIMIT || '1000'),
    encryptionKey: process.env.LOG_ENCRYPTION_KEY
  }
}
```

---

## ğŸ§ª ãƒ†ã‚¹ãƒˆå®Ÿè£…

### **1. å˜ä½“ãƒ†ã‚¹ãƒˆä¾‹**

```typescript
// tests/log-system.test.ts
import { describe, it, expect, beforeEach, afterEach } from 'vitest'
import { LogQueue } from '~/server/utils/log-queue'
import { UnifiedDatabase } from '~/server/utils/unified-database'

describe('Log System', () => {
  beforeEach(async () => {
    // ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
    await UnifiedDatabase.getInstance().query('BEGIN')
  })

  afterEach(async () => {
    // ãƒ†ã‚¹ãƒˆå¾Œã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    await UnifiedDatabase.getInstance().query('ROLLBACK')
  })

  it('should record auth log successfully', async () => {
    const logData = {
      system: 'saas',
      tenant_id: 'test-tenant-uuid',
      user_id: 'test-user-uuid',
      email: 'test@example.com',
      action: 'LOGIN_SUCCESS',
      ip_address: '192.168.1.1'
    }

    await LogQueue.enqueue('auth_log', logData)
    
    // ã‚­ãƒ¥ãƒ¼å‡¦ç†ã‚’å¾…æ©Ÿ
    await new Promise(resolve => setTimeout(resolve, 2000))

    const result = await UnifiedDatabase.getInstance().query(
      'SELECT * FROM auth_logs WHERE user_id = $1',
      [logData.user_id]
    )

    expect(result.rows).toHaveLength(1)
    expect(result.rows[0].action).toBe('LOGIN_SUCCESS')
  })

  it('should handle security log with alert', async () => {
    const logData = {
      system: 'saas',
      tenant_id: 'test-tenant-uuid',
      event_type: 'UNAUTHORIZED_ACCESS',
      severity: 'HIGH',
      description: 'Test security incident'
    }

    await LogQueue.enqueue('security_log', logData)
    
    // ã‚¢ãƒ©ãƒ¼ãƒˆãŒé€ä¿¡ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
    // ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ã‚¢ãƒ©ãƒ¼ãƒˆã‚µãƒ¼ãƒ“ã‚¹ã‚’ãƒ¢ãƒƒã‚¯åŒ–ï¼‰
  })
})
```

---

## ğŸ“‹ ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

### **1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**

```sql
-- migrations/001_create_log_tables.sql
-- ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã¯ä¸Šè¨˜ã®ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆSQLã¨åŒã˜

-- migrations/002_create_partitions.sql
-- åˆæœŸãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ä½œæˆ
SELECT create_auth_logs_partition('2025-09-01'::DATE);
SELECT create_auth_logs_partition('2025-10-01'::DATE);
SELECT create_auth_logs_partition('2025-11-01'::DATE);

-- è‡ªå‹•ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ä½œæˆã®cronè¨­å®š
-- æ¯æœˆ1æ—¥ã«æ¬¡æœˆã®ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
-- 0 0 1 * * SELECT create_auth_logs_partition(CURRENT_DATE + INTERVAL '1 month');
```

### **2. ãƒ‡ãƒ—ãƒ­ã‚¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**

```bash
#!/bin/bash
# deploy-log-system.sh

set -e

echo "ğŸš€ Deploying Log System..."

# 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
echo "ğŸ“Š Running database migrations..."
psql $LOG_DB_URL -f migrations/001_create_log_tables.sql
psql $LOG_DB_URL -f migrations/002_create_partitions.sql

# 2. Redisè¨­å®šç¢ºèª
echo "ğŸ”§ Checking Redis connection..."
redis-cli -u $REDIS_LOG_QUEUE_URL ping

# 3. ç’°å¢ƒå¤‰æ•°ç¢ºèª
echo "âš™ï¸ Validating environment variables..."
required_vars=(
  "LOG_DB_HOST"
  "LOG_DB_NAME" 
  "REDIS_LOG_QUEUE_URL"
  "SLACK_SECURITY_WEBHOOK_URL"
)

for var in "${required_vars[@]}"; do
  if [ -z "${!var}" ]; then
    echo "âŒ Missing required environment variable: $var"
    exit 1
  fi
done

# 4. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ—ãƒ­ã‚¤
echo "ğŸ—ï¸ Deploying application..."
npm run build
pm2 restart hotel-common-log-system

# 5. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
echo "ğŸ¥ Running health checks..."
sleep 10
curl -f http://localhost:3400/api/v1/logs/health || exit 1

echo "âœ… Log System deployment completed successfully!"
```

ã“ã®æŠ€è¡“å®Ÿè£…è©³ç´°æ›¸ã«ã‚ˆã‚Šã€é–‹ç™ºãƒãƒ¼ãƒ ã¯è³ªå•ã™ã‚‹ã“ã¨ãªãå®Œå…¨ãªå®Ÿè£…ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚
